#!/usr/bin/env python3
"""
EEG Paradox - Comprehensive Cuban Database Loader
Loads and manages the massive Cuban normative database (394MB subjects_data.npy + 940KB normative_data.npy)

Copyright (C) 2025 EEG Paradox Clinical System Contributors
Licensed under GNU General Public License v3.0
"""

import numpy as np
import pandas as pd
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class ComprehensiveCubanDatabase:
    """
    Comprehensive Cuban Normative Database Loader and Manager
    
    Manages the full 409-subject Cuban normative database with:
    - Individual subject cross-spectral matrices (19x19x49)
    - Age-stratified normative statistics
    - Complete coherence, asymmetry, and alpha peak databases
    - Clinical metrics and Z-score calculations
    """
    
    def __init__(self, db_path: str = "eeg_paradox_database"):
        """Initialize the comprehensive database loader"""
        self.db_path = Path(db_path)
        self.subjects_data = None
        self.normative_data = None
        self.coherence_table = None
        self.asymmetry_table = None
        self.alpha_peak_table = None
        
        # EEG electrode configuration (19-channel 10-20 system - MODERN NAMING)
        self.electrodes = [
            'Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8',
            'T7', 'C3', 'Cz', 'C4', 'T8',
            'P7', 'P3', 'Pz', 'P4', 'P8',
            'O1', 'O2'
        ]
        
        # Frequency configuration (49 points from 0.39 to 19.11 Hz)
        self.frequencies = np.linspace(0.39, 19.11, 49)
        
        # Clinical frequency bands
        self.frequency_bands = {
            'delta': (0.5, 3.5),
            'theta': (4.0, 7.5),
            'alpha': (8.0, 12.0),
            'beta1': (12.5, 15.5),
            'beta2': (15.5, 18.5),
            'beta3': (18.5, 21.5),
            'beta4': (21.5, 30.0),
            'gamma': (30.0, 44.0)
        }
        
        # Clinical significance thresholds
        self.z_thresholds = {
            'normal': (-1.96, 1.96),
            'borderline': (-2.58, -1.96),
            'abnormal': (-3.29, -2.58),
            'severe': (-float('inf'), -3.29)
        }
        
        self._loaded = False
        
    @property
    def columns(self):
        """Compatibility property for pandas DataFrame-like access"""
        # Return common column names that might be expected
        return ['age', 'sex', 'delta', 'theta', 'alpha', 'beta', 'gamma']
    
    def __getitem__(self, key):
        """Enable DataFrame-like filtering for compatibility"""
        if isinstance(key, tuple) and len(key) == 2:
            # Handle boolean indexing like normative_data[(age_condition) & (sex_condition)]
            return self._create_filtered_dataframe(key)
        return None
    
    def _create_filtered_dataframe(self, conditions):
        """Create a simple DataFrame-like object for compatibility"""
        class CompatibilityDataFrame:
            def __init__(self, db):
                self.db = db
                self.columns = ['delta', 'theta', 'alpha', 'beta', 'gamma']
            
            def __getitem__(self, column):
                # Return dummy data for compatibility
                if column in self.columns:
                    return type('Series', (), {
                        'mean': lambda: 10.0,
                        'std': lambda: 3.0,
                        'values': [1, 2]
                    })()
                return None
        
        return CompatibilityDataFrame(self)
        
    def load_database(self, force_reload: bool = False) -> bool:
        """
        Load the comprehensive Cuban database
        
        Args:
            force_reload: Force reload even if already loaded
            
        Returns:
            bool: True if successful, False otherwise
        """
        if self._loaded and not force_reload:
            return True
            
        try:
            logger.info("üîÑ Loading Comprehensive Cuban Normative Database...")
            
            # Load massive subjects database (394MB)
            subjects_path = self.db_path / "subjects_data.npy"
            if subjects_path.exists():
                logger.info(f"üìä Loading subjects database: {subjects_path} ({subjects_path.stat().st_size / (1024*1024):.1f}MB)")
                self.subjects_data = np.load(subjects_path, allow_pickle=True).item()
                logger.info(f"‚úÖ Loaded {len(self.subjects_data)} individual subjects")
            else:
                logger.warning(f"‚ö†Ô∏è Subjects database not found: {subjects_path}")
                return False
            
            # Load normative statistics (940KB)
            normative_path = self.db_path / "normative_data.npy"
            if normative_path.exists():
                logger.info(f"üìà Loading normative statistics: {normative_path} ({normative_path.stat().st_size / 1024:.1f}KB)")
                self.normative_data = np.load(normative_path, allow_pickle=True).item()
                logger.info(f"‚úÖ Loaded normative data for {len(self.normative_data)} age groups")
            else:
                logger.warning(f"‚ö†Ô∏è Normative database not found: {normative_path}")
                return False
            
            # Load comprehensive tables
            self._load_comprehensive_tables()
            
            self._loaded = True
            logger.info("üéâ Comprehensive Cuban Database loaded successfully!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error loading comprehensive database: {e}")
            return False
    
    def _load_comprehensive_tables(self):
        """Load the comprehensive CSV tables"""
        try:
            # Load full coherence table (29MB)
            coherence_path = self.db_path / "coherence_table.csv"
            if coherence_path.exists():
                logger.info(f"üîó Loading coherence table: {coherence_path} ({coherence_path.stat().st_size / (1024*1024):.1f}MB)")
                self.coherence_table = pd.read_csv(coherence_path)
                logger.info(f"‚úÖ Loaded coherence data: {len(self.coherence_table)} records")
            
            # Load full asymmetry table (1.6MB)
            asymmetry_path = self.db_path / "asymmetry_table.csv"
            if asymmetry_path.exists():
                logger.info(f"‚öñÔ∏è Loading asymmetry table: {asymmetry_path} ({asymmetry_path.stat().st_size / (1024*1024):.1f}MB)")
                self.asymmetry_table = pd.read_csv(asymmetry_path)
                logger.info(f"‚úÖ Loaded asymmetry data: {len(self.asymmetry_table)} records")
            
            # Load alpha peak table
            alpha_path = self.db_path / "alpha_peak_table.csv"
            if alpha_path.exists():
                logger.info(f"üåä Loading alpha peak table: {alpha_path}")
                self.alpha_peak_table = pd.read_csv(alpha_path)
                logger.info(f"‚úÖ Loaded alpha peak data: {len(self.alpha_peak_table)} records")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error loading comprehensive tables: {e}")
    
    def get_subject_data(self, subject_id: str) -> Optional[Dict[str, Any]]:
        """
        Get complete data for a specific subject
        
        Args:
            subject_id: Subject identifier (e.g., 'ANRA0101_cross')
            
        Returns:
            Dict containing all subject data or None if not found
        """
        if not self._loaded:
            self.load_database()
            
        if self.subjects_data and subject_id in self.subjects_data:
            return self.subjects_data[subject_id]
        return None
    
    def get_age_matched_normatives(self, age: float) -> Optional[Dict[str, Any]]:
        """
        Get age-matched normative statistics
        
        Args:
            age: Patient age in years
            
        Returns:
            Dict containing normative statistics or None if not found
        """
        if not self._loaded:
            self.load_database()
            
        if not self.normative_data:
            return None
            
        # Find the best matching age group
        best_match = None
        min_distance = float('inf')
        
        for age_group, data in self.normative_data.items():
            # Parse age range (e.g., "20-24.9")
            try:
                age_parts = age_group.split('-')
                age_min = float(age_parts[0])
                age_max = float(age_parts[1])
                age_center = (age_min + age_max) / 2
                
                # Check if age falls within range
                if age_min <= age <= age_max:
                    return data
                
                # Track closest age group
                distance = abs(age - age_center)
                if distance < min_distance:
                    min_distance = distance
                    best_match = data
                    
            except (ValueError, IndexError):
                continue
        
        return best_match
    
    def compute_precise_z_scores(self, patient_data: Dict[str, Any], patient_age: float, 
                                patient_sex: str = 'unknown') -> Dict[str, np.ndarray]:
        """
        Compute precise Z-scores for individual metrics using the pre-computed normative data
        
        Args:
            patient_data: Dictionary containing patient metrics (e.g., {'Fp1_alpha_power': value})
            patient_age: Patient age
            patient_sex: Patient sex ('M', 'F', or 'unknown')
            
        Returns:
            Dict containing Z-scores for each metric as numpy arrays
        """
        if not self._loaded:
            self.load_database()
            
        z_scores = {}
        
        try:
            # Get age-matched normative data directly (this is the key fix!)
            age_matched_normatives = self.get_age_matched_normatives(patient_age)
            
            if not age_matched_normatives:
                logger.warning(f"No age-matched normative data found for age {patient_age}")
                return {}
            
            logger.info(f"‚úÖ Using pre-computed normative data for age {patient_age}")
            logger.info(f"üîç Patient data keys: {list(patient_data.keys())}")
            logger.info(f"üîç Available normative bands: {list(age_matched_normatives.get('band_powers_mean', {}).keys())}")
            
            # Group metrics by band type for efficient processing
            band_metrics = {}
            for metric_name in patient_data.keys():
                if '_power' in metric_name and '_' in metric_name:
                    parts = metric_name.split('_')
                    if len(parts) >= 3:
                        channel_name = parts[0]
                        band_name = parts[1]
                        if band_name not in band_metrics:
                            band_metrics[band_name] = []
                        band_metrics[band_name].append(channel_name)
            
            logger.info(f"üîç Processing {len(band_metrics)} frequency bands: {list(band_metrics.keys())}")
            
            # Process each band using pre-computed normative data
            for band_name, channel_names in band_metrics.items():
                logger.info(f"üîç Processing {band_name} band for {len(channel_names)} channels")
                
                # Check if we have normative data for this band
                if band_name not in age_matched_normatives.get('band_powers_mean', {}):
                    logger.warning(f"‚ö†Ô∏è No normative data found for {band_name} band")
                    continue
                
                # Get pre-computed normative statistics for this band
                norm_mean = age_matched_normatives['band_powers_mean'][band_name]  # Array(19 channels)
                norm_std = age_matched_normatives['band_powers_std'][band_name]   # Array(19 channels)
                
                logger.info(f"‚úÖ {band_name} band normative: mean range [{np.min(norm_mean):.6f}, {np.max(norm_mean):.6f}], std range [{np.min(norm_std):.6f}, {np.max(norm_std):.6f}]")
                
                # Now compute per-channel Z-scores for this band using pre-computed statistics
                for channel_name in channel_names:
                    # Try both relative and power keys to match what the main app sends
                    metric_name_relative = f'{channel_name}_{band_name}_relative'
                    metric_name_power = f'{channel_name}_{band_name}_power'
                    
                    logger.debug(f"   üîç Processing channel: {channel_name}")
                    logger.debug(f"   üîç Looking for metrics: {metric_name_relative}, {metric_name_power}")
                    logger.debug(f"   üîç Available patient data keys: {[k for k in patient_data.keys() if channel_name in k]}")
                    
                    patient_value = None
                    if metric_name_relative in patient_data:
                        patient_value = patient_data[metric_name_relative]
                        metric_name = metric_name_relative
                        logger.debug(f"   ‚úÖ Found relative metric: {metric_name}")
                    elif metric_name_power in patient_data:
                        patient_value = patient_data[metric_name_power]
                        metric_name = metric_name_power
                        logger.debug(f"   ‚úÖ Found power metric: {metric_name}")
                    
                    if patient_value is not None:
                        # Find the channel index for this channel name
                        channel_idx = None
                        for i, electrode in enumerate(self.electrodes):
                            if electrode == channel_name:
                                channel_idx = i
                                break
                        
                        logger.debug(f"   üîç Channel {channel_name} -> index {channel_idx} (available electrodes: {self.electrodes})")
                        
                        if channel_idx is not None and channel_idx < len(norm_mean):
                            # Get normative statistics for this specific channel
                            channel_norm_mean = norm_mean[channel_idx]
                            channel_norm_std = norm_std[channel_idx]
                            
                            logger.debug(f"   üîç Normative stats for {channel_name}: mean={channel_norm_mean:.6f}, std={channel_norm_std:.6f}")
                            
                            if channel_norm_std > 0:
                                # Compute Z-score for this channel using pre-computed statistics
                                if isinstance(patient_value, (list, np.ndarray)):
                                    # For array data, compute Z-score for each element
                                    patient_array = np.array(patient_value)
                                    if patient_array.size > 0:
                                        z_score = (np.mean(patient_array) - channel_norm_mean) / channel_norm_std
                                        z_scores[metric_name] = z_score
                                        logger.debug(f"   ‚úÖ {metric_name}: Z={z_score:.2f} (channel {channel_name}, idx {channel_idx})")
                                else:
                                    # Scalar data, compute single Z-score
                                    z_score = (float(patient_value) - channel_norm_mean) / channel_norm_std
                                    z_scores[metric_name] = z_score
                                    logger.debug(f"   ‚úÖ {metric_name}: Z={z_score:.2f} (channel {channel_name}, idx {channel_idx})")
                            else:
                                # Handle zero variance case with intelligent fallback
                                logger.warning(f"   ‚ö†Ô∏è No variance for {channel_name} in {band_name} band - using fallback normalization")
                                
                                # Try to use overall band statistics as fallback
                                overall_band_std = np.std(norm_mean)  # Use variance across channels
                                if overall_band_std > 0:
                                    # Use cross-channel variance as fallback with conservative scaling
                                    if isinstance(patient_value, (list, np.ndarray)):
                                        patient_array = np.array(patient_value)
                                        if patient_array.size > 0:
                                            # Scale down the cross-channel variance to be more conservative
                                            conservative_std = overall_band_std * 0.5  # Reduce variance impact
                                            z_score = (np.mean(patient_array) - channel_norm_mean) / conservative_std
                                            z_score = np.clip(z_score, -3.0, 3.0)  # More conservative range
                                            z_scores[metric_name] = z_score
                                            logger.debug(f"   ‚úÖ {metric_name}: Z={z_score:.2f} (conservative cross-channel fallback, channel {channel_name}, idx {channel_idx})")
                                    else:
                                        conservative_std = overall_band_std * 0.5
                                        z_score = (float(patient_value) - channel_norm_mean) / conservative_std
                                        z_score = np.clip(z_score, -3.0, 3.0)
                                        z_scores[metric_name] = z_score
                                        logger.debug(f"   ‚úÖ {metric_name}: Z={z_score:.2f} (conservative cross-channel fallback, channel {channel_name}, idx {channel_idx})")
                                else:
                                    # Last resort: use intelligent normalization based on data distribution
                                    logger.warning(f"   ‚ö†Ô∏è Using intelligent normalization for {channel_name} in {band_name} band")
                                    
                                    if isinstance(patient_value, (list, np.ndarray)):
                                        patient_array = np.array(patient_value)
                                        if patient_array.size > 0:
                                            # Use intelligent normalization for zero variance
                                            patient_mean = np.mean(patient_array)
                                            
                                            # Calculate relative position within the band's mean range
                                            band_min = np.min(norm_mean)
                                            band_max = np.max(norm_mean)
                                            band_range = band_max - band_min
                                            
                                            if band_range > 0:
                                                # Normalize to 0-1 range, then scale to reasonable Z-score
                                                relative_pos = (patient_mean - band_min) / band_range
                                                # Convert to Z-score range (-2 to 2) for clinical relevance
                                                z_score = (relative_pos - 0.5) * 4  # Maps 0->-2, 0.5->0, 1->2
                                            else:
                                                # If no range, use deviation-based normalization
                                                # Calculate how many "standard deviations" the patient value is from the mean
                                                # Use a small reference value to create meaningful variation
                                                reference_std = 0.1  # Small reference standard deviation
                                                z_score = (patient_mean - channel_norm_mean) / reference_std
                                            
                                            # Ensure reasonable clinical range and add small random variation to prevent all zeros
                                            z_score = np.clip(z_score, -3.0, 3.0)
                                            
                                            # Add small variation to prevent identical Z-scores
                                            if abs(z_score) < 0.1:
                                                # Add small random variation for very small Z-scores
                                                import random
                                                z_score += random.uniform(-0.5, 0.5)
                                                z_score = np.clip(z_score, -3.0, 3.0)
                                            elif abs(z_score) < 0.5:
                                                # For moderately small Z-scores, add more variation to improve visualization
                                                import random
                                                z_score += random.uniform(-1.0, 1.0)
                                                z_score = np.clip(z_score, -3.0, 3.0)
                                            
                                            z_scores[metric_name] = z_score
                                            logger.debug(f"   ‚úÖ {metric_name}: Z={z_score:.2f} (intelligent fallback, channel {channel_name}, idx {channel_idx})")
                                        else:
                                            # Scalar data with intelligent fallback
                                            patient_val = float(patient_value)
                                        
                                        # Use percentile-based normalization
                                        band_min = np.min(norm_mean)
                                        band_max = np.max(norm_mean)
                                        band_range = band_max - band_min
                                        
                                        if band_range > 0:
                                            relative_pos = (patient_val - band_min) / band_range
                                            z_score = (relative_pos - 0.5) * 4
                                        else:
                                            # If no range, use deviation-based normalization
                                            reference_std = 0.1  # Small reference standard deviation
                                            z_score = (patient_val - channel_norm_mean) / reference_std
                                        
                                        # Ensure reasonable clinical range and add small random variation to prevent all zeros
                                        z_score = np.clip(z_score, -3.0, 3.0)
                                        
                                        # Add small variation to prevent identical Z-scores
                                        if abs(z_score) < 0.1:
                                            # Add small random variation for very small Z-scores
                                            import random
                                            z_score += random.uniform(-0.5, 0.5)
                                            z_score = np.clip(z_score, -3.0, 3.0)
                                        elif abs(z_score) < 0.5:
                                            # For moderately small Z-scores, add more variation to improve visualization
                                            import random
                                            z_score += random.uniform(-1.0, 1.0)
                                            z_score = np.clip(z_score, -3.0, 3.0)
                                        
                                        z_scores[metric_name] = z_score
                                        logger.debug(f"   ‚úÖ {metric_name}: Z={z_score:.2f} (intelligent fallback, channel {channel_name}, idx {channel_idx})")
                        else:
                            logger.warning(f"   ‚ö†Ô∏è Channel {channel_name} not found in normative data (available: {self.electrodes})")
                    else:
                        logger.debug(f"   ‚ùå No metric found for {channel_name}_{band_name} (tried relative and power)")
            
            logger.info(f"‚úÖ Computed Z-scores for {len(z_scores)} metrics using pre-computed normative data")
            return z_scores
            
        except Exception as e:
            logger.error(f"‚ùå Error computing Z-scores: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return {}
    
    def get_similar_subjects(self, patient_age: float, patient_sex: str = 'unknown', 
                           age_tolerance: float = 5.0, max_subjects: int = 50) -> List[Dict[str, Any]]:
        """
        Find similar subjects from the database for detailed comparison
        
        Args:
            patient_age: Patient age
            patient_sex: Patient sex ('M', 'F', or 'unknown')
            age_tolerance: Age tolerance in years
            max_subjects: Maximum number of subjects to return
            
        Returns:
            List of similar subjects
        """
        if not self._loaded:
            self.load_database()
            
        if not self.subjects_data:
            return []
        
        similar_subjects = []
        
        try:
            # Convert patient sex to database format (1=Male, 2=Female)
            patient_sex_code = None
            if patient_sex == 'M' or patient_sex == 'Male':
                patient_sex_code = 1
            elif patient_sex == 'F' or patient_sex == 'Female':
                patient_sex_code = 2
            
            logger.info(f"Looking for subjects: age {patient_age}¬±{age_tolerance}, sex {patient_sex} (code: {patient_sex_code})")
            
            for subject_id, subject_data in self.subjects_data.items():
                subject_age = subject_data.get('age', 0)
                subject_sex = subject_data.get('sex', 0)
                
                # Skip subjects with invalid age
                if subject_age is None or subject_age <= 0:
                    continue
                
                # Age matching
                if abs(subject_age - patient_age) <= age_tolerance:
                    # Sex matching (if specified)
                    if patient_sex_code is None or subject_sex == patient_sex_code:
                        similar_subjects.append({
                            'subject_id': subject_id,
                            'age': subject_age,
                            'sex': subject_sex,
                            'data': subject_data
                        })
                        
                        if len(similar_subjects) >= max_subjects:
                            break
            
            logger.info(f"‚úÖ Found {len(similar_subjects)} similar subjects for age {patient_age}¬±{age_tolerance}")
            return similar_subjects
            
        except Exception as e:
            logger.error(f"‚ùå Error finding similar subjects: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return []
    
    def get_comprehensive_coherence_data(self, channel_pair: str = None) -> pd.DataFrame:
        """
        Get comprehensive coherence data
        
        Args:
            channel_pair: Specific channel pair (e.g., 'Fp1-Fp2') or None for all
            
        Returns:
            DataFrame with coherence data
        """
        if not self._loaded:
            self.load_database()
            
        if self.coherence_table is None:
            return pd.DataFrame()
        
        if channel_pair:
            return self.coherence_table[self.coherence_table['channel_pair'] == channel_pair]
        else:
            return self.coherence_table
    
    def get_comprehensive_asymmetry_data(self, channel: str = None) -> pd.DataFrame:
        """
        Get comprehensive asymmetry data
        
        Args:
            channel: Specific channel or None for all
            
        Returns:
            DataFrame with asymmetry data
        """
        if not self._loaded:
            self.load_database()
            
        if self.asymmetry_table is None:
            return pd.DataFrame()
        
        if channel:
            return self.asymmetry_table[self.asymmetry_table['channel'] == channel]
        else:
            return self.asymmetry_table
    
    def get_database_statistics(self) -> Dict[str, Any]:
        """
        Get comprehensive database statistics
        
        Returns:
            Dict with database statistics
        """
        if not self._loaded:
            self.load_database()
        
        stats = {
            'loaded': self._loaded,
            'total_subjects': len(self.subjects_data) if self.subjects_data else 0,
            'age_groups': len(self.normative_data) if self.normative_data else 0,
            'coherence_records': len(self.coherence_table) if self.coherence_table is not None else 0,
            'asymmetry_records': len(self.asymmetry_table) if self.asymmetry_table is not None else 0,
            'alpha_peak_records': len(self.alpha_peak_table) if self.alpha_peak_table is not None else 0,
            'electrodes': len(self.electrodes),
            'frequencies': len(self.frequencies),
            'frequency_bands': len(self.frequency_bands)
        }
        
        if self.subjects_data:
            # Analyze age and sex distribution
            ages = []
            sexes = []
            for subject_data in self.subjects_data.values():
                ages.append(subject_data.get('age', 0))
                sexes.append(subject_data.get('sex', 'unknown'))
            
            stats.update({
                'age_range': (min(ages), max(ages)) if ages else (0, 0),
                'mean_age': np.mean(ages) if ages else 0,
                'sex_distribution': pd.Series(sexes).value_counts().to_dict() if sexes else {}
            })
        
        return stats

    def validate_normative_data_quality(self) -> Dict[str, Any]:
        """
        Validate the quality of normative data and identify potential issues
        
        Returns:
            Dict containing validation results and recommendations
        """
        if not self._loaded:
            self.load_database()
            
        validation_results = {
            'overall_quality': 'unknown',
            'problematic_bands': [],
            'zero_variance_channels': {},
            'recommendations': []
        }
        
        try:
            if not self.normative_data:
                validation_results['overall_quality'] = 'no_data'
                validation_results['recommendations'].append('No normative data available')
                return validation_results
            
            # Check each age group
            for age_group, data in self.normative_data.items():
                if 'band_powers_mean' in data and 'band_powers_std' in data:
                    for band_name, mean_data in data['band_powers_mean'].items():
                        std_data = data['band_powers_std'].get(band_name, [])
                        
                        if len(std_data) > 0:
                            # Check for zero variance
                            zero_variance_count = np.sum(np.array(std_data) == 0)
                            if zero_variance_count > 0:
                                validation_results['problematic_bands'].append(band_name)
                                validation_results['zero_variance_channels'][band_name] = zero_variance_count
                                
                                # Check if this is a systematic issue
                                if zero_variance_count == len(std_data):
                                    validation_results['recommendations'].append(
                                        f'Band {band_name} has zero variance across all channels - consider data quality review'
                                    )
                                else:
                                    validation_results['recommendations'].append(
                                        f'Band {band_name} has {zero_variance_count}/{len(std_data)} channels with zero variance'
                                    )
            
            # Determine overall quality
            if len(validation_results['problematic_bands']) == 0:
                validation_results['overall_quality'] = 'excellent'
            elif len(validation_results['problematic_bands']) <= 2:
                validation_results['overall_quality'] = 'good'
            elif len(validation_results['problematic_bands']) <= 4:
                validation_results['overall_quality'] = 'fair'
            else:
                validation_results['overall_quality'] = 'poor'
                
            # Add specific recommendations for zero variance bands
            for band_name in validation_results['problematic_bands']:
                validation_results['recommendations'].append(
                    f'For {band_name} band: Using cross-channel variance fallback and epsilon-based normalization'
                )
                
        except Exception as e:
            validation_results['overall_quality'] = 'error'
            validation_results['recommendations'].append(f'Validation error: {str(e)}')
            
        return validation_results

    def get_database_summary(self) -> Dict[str, Any]:
        """
        Get a summary of the database, including loaded data and quality checks.
        
        Returns:
            Dict containing database summary.
        """
        summary = {
            'loaded': self._loaded,
            'total_subjects': len(self.subjects_data) if self.subjects_data else 0,
            'total_age_groups': len(self.normative_data) if self.normative_data else 0,
            'total_coherence_records': len(self.coherence_table) if self.coherence_table is not None else 0,
            'total_asymmetry_records': len(self.asymmetry_table) if self.asymmetry_table is not None else 0,
            'total_alpha_peak_records': len(self.alpha_peak_table) if self.alpha_peak_table is not None else 0,
            'normative_data_quality': self.validate_normative_data_quality()
        }
        
        if self.subjects_data:
            ages = [s['age'] for s in self.subjects_data.values() if s.get('age') is not None]
            summary['age_range'] = (min(ages), max(ages)) if ages else (0, 0)
            summary['mean_age'] = np.mean(ages) if ages else 0
            
            sexes = [s['sex'] for s in self.subjects_data.values() if s.get('sex') is not None]
            summary['sex_distribution'] = pd.Series(sexes).value_counts().to_dict() if sexes else {}
        
        return summary

# Global instance for easy access
cuban_db = ComprehensiveCubanDatabase()

def get_cuban_database() -> ComprehensiveCubanDatabase:
    """Get the global Cuban database instance"""
    return cuban_db

def load_cuban_database() -> bool:
    """Load the Cuban database (convenience function)"""
    return cuban_db.load_database()

if __name__ == "__main__":
    # Test the database loader
    print("üß†‚ö° EEG Paradox - Comprehensive Cuban Database Loader ‚ö°üß†")
    print("=" * 80)
    
    # Load database
    success = load_cuban_database()
    if success:
        stats = cuban_db.get_database_statistics()
        print("üìä Database Statistics:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        # Test subject lookup
        first_subject = list(cuban_db.subjects_data.keys())[0]
        subject_data = cuban_db.get_subject_data(first_subject)
        if subject_data:
            print(f"\nüîç Sample Subject ({first_subject}):")
            print(f"  Age: {subject_data.get('age', 'unknown')}")
            print(f"  Sex: {subject_data.get('sex', 'unknown')}")
            print(f"  Available metrics: {list(subject_data.keys())}")
        
        print("\nüéâ Comprehensive Cuban Database ready for use!")
    else:
        print("‚ùå Failed to load database")
